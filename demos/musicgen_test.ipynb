{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nao/anaconda3/envs/audiocraft/lib/python3.9/site-packages/torch/nn/utils/weight_norm.py:30: UserWarning: torch.nn.utils.weight_norm is deprecated in favor of torch.nn.utils.parametrizations.weight_norm.\n",
      "  warnings.warn(\"torch.nn.utils.weight_norm is deprecated in favor of torch.nn.utils.parametrizations.weight_norm.\")\n"
     ]
    }
   ],
   "source": [
    "from audiocraft.data.audio import audio_write\n",
    "import IPython.display as ipd\n",
    "from audiocraft.models import MusicGen, MultiBandDiffusion\n",
    "import numpy as np\n",
    "\n",
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
    "# pip install torch==2.1.2 torchvision==0.16.2 torchaudio==2.1.2 --index-url https://download.pytorch.org/whl/cu118\n",
    "\n",
    "# load your finetune\n",
    "#musicgen = MusicGen.get_pretrained('./checkpoints/finetune')\n",
    "musicgen = MusicGen.get_pretrained('facebook/musicgen-large')\n",
    "\n",
    "musicgen.set_generation_params(duration=10)\n",
    "mbd = MultiBandDiffusion.get_mbd_musicgen()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import openai\n",
    "import json\n",
    "\n",
    "# Initialize OpenAI API key\n",
    "openai.api_key = \"\"  # Replace with your actual API key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prompt_sample = f\"\"\"\"\"I need text prompts for MusicGen, text-to-music model. I want to generate minimal techno, house, bass, garage music. Please give me 3 text promots and put in a python array. I like music with the combinations of two of the following characteristics, but please rephrase these words:\n",
    "# groovy, bouncy, bassy, dubby, glitchy, jazzy, minimal, experimental, happy, tropical. BPM should be inbetween 110 to 135. Get creative and use random instruments! \n",
    "# \"\"\"\"\"\n",
    "\n",
    "# # prompt_input = f\"\"\"\"\"\n",
    "# # Summerize '{item['text']}' and format the caption with other information into a JSON file.\n",
    "# #\"\"\"\"\"\n",
    "# example_captions = [\n",
    "#     \"A 120 BPM upbeat techno track.\",\n",
    "#     \"A 130 BPM smooth house music tune with a soothing saxophone solo, mellow piano chords, and soft percussion.\",\n",
    "#     \"A heartwarming folk tune with soothing harmonies and gentle acoustic melodies, perfect for a relaxing afternoon in the countryside.\",\n",
    "# ]\n",
    "\n",
    "# prompt_sample = f\"\"\"\"\"I need text prompts for MusicGen, text-to-music model. I want to generate various percussion loops. Please give me 3 text promots and put in a python array. BPM should be inbetween 110 to 135. Get creative and use random instruments! \n",
    "# \"\"\"\"\"\n",
    "\n",
    "# prompt_sample = f\"\"\"\"\"I need text prompts for MusicGen, text-to-music model. I want to generate various melody loops than contain no drums nor percussions. Please give me 3 text promots and put in a python array. BPM should be inbetween 110 to 135. Be specific, get creative and use random instruments! \n",
    "# \"\"\"\"\"\n",
    "\n",
    "prompt_sample = f\"\"\"\"\"I need text prompts for MusicGen, text-to-music model. \\\n",
    "    Please give me 3 text promots and put in a python array. \n",
    "    It should be dance music such as house, techno, dubstep, juke, breakbeats, drum and bass, jungle, garage, etc. \\ \n",
    "    I want make them experimental, but not too glitchy. It should be catchy, weird and pop and escpecially bassy. \\\n",
    "    please use lots of random instruments and effects. \n",
    "    BPM should be inbetween 110 to 180. Be specific, get creative and use random instruments! \\\n",
    "\"\"\"\"\"\n",
    "\n",
    "\n",
    "# prompt_input = f\"\"\"\"\"\n",
    "# Summerize '{item['text']}' and format the caption with other information into a JSON file.\n",
    "#\"\"\"\"\"\n",
    "example_captions = [\n",
    "    \"African percussion drums with 808 bass and Shakuhachi, bpm 120\",\n",
    "    \"Japanese taiko in jungle music with heavy bass in 2050, bpm 170\",\n",
    "    \"A very groovy garage beat with a deep bassline and a catchy melody, bpm 140\"\n",
    "]\n",
    "\n",
    "\n",
    "def get_captions():\n",
    "    # Query\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are a world-famous dance music DJ.\"},\n",
    "            {\"role\": \"user\", \"content\": f\"{prompt_sample}\"},\n",
    "            {\"role\": \"assistant\", \"content\": f\"{example_captions}\"},\n",
    "            {\"role\": \"user\", \"content\": f\"{prompt_sample}\"},\n",
    "        ]\n",
    "    )\n",
    "    #print(response)\n",
    "\n",
    "    # Extract caption from API response\n",
    "    json_output = response['choices'][0]['message']['content'].strip()\n",
    "    json_output = json_output.replace('\\'', '\\\"')\n",
    "    json_output = json.loads(json_output)\n",
    "    print(json_output, type(json_output))\n",
    "    return json_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Example 1: unconditional generation\n",
    "# #torch.manual_seed(12)\n",
    "\n",
    "# wavs, tokens = musicgen.generate_unconditional(4, return_tokens=True)\n",
    "# wav_diffusion = mbd.tokens_to_wav(tokens)\n",
    "# #print(tokens.shape)\n",
    "\n",
    "# # save and display generated audio\n",
    "# for idx, one_wav in enumerate(wavs):\n",
    "#     audio_write(f'{idx}', one_wav.cpu(), musicgen.sample_rate, strategy=\"loudness\", loudness_compressor=True)\n",
    "#     ipd.display(ipd.Audio(one_wav.cpu(), rate=32000))\n",
    "#     audio_write(f'{idx}_diffusion', wav_diffusion[idx].cpu(), musicgen.sample_rate, strategy=\"loudness\", loudness_compressor=True)\n",
    "\n",
    "#     ipd.display(ipd.Audio(wav_diffusion[idx].detach().cpu(), rate=32000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Futuristic techno groove with distorted trumpet solo and pulsating bassline, bpm 150', 'Dubstep wobble bass meets accordion melody in a dark alley, bpm 130', 'Experimental breakbeats with sitar riffs and laser sound effects, bpm 160'] <class 'list'>\n"
     ]
    }
   ],
   "source": [
    "# Example 2: text guided generation\n",
    "# import torch\n",
    "# torch.manual_seed(12)\n",
    "\n",
    "# wavs, tokens = musicgen.generate([\n",
    "# 'Techno music, A midnight jazz club ambiance with minimal techno vibes.',\n",
    "# 'House music, Deep basslines and dubby echoes in a warehouse setting.',\n",
    "# 'House music, Serene beach sunset translated into minimal house melodies.',\n",
    "# 'Techno music, Syncopated beats and smooth chord progressions, a jazzy touch.'\n",
    "# ], return_tokens=True)\n",
    "from IPython.display import clear_output\n",
    "\n",
    "musicgen.set_generation_params(duration=14.0)\n",
    "\n",
    "output_dir = 'generated_drums2'\n",
    "\n",
    "for i in range(5000):\n",
    "    try: \n",
    "        captions = get_captions()\n",
    "\n",
    "        wavs, tokens = musicgen.generate(captions, return_tokens=True)\n",
    "        wav_diffusion = mbd.tokens_to_wav(tokens)\n",
    "\n",
    "        # save and display generated audio\n",
    "        for idx, one_wav in enumerate(wavs):\n",
    "            audio_write(f'{idx}', one_wav.cpu(), musicgen.sample_rate, strategy=\"loudness\", loudness_compressor=True)\n",
    "            ipd.display(ipd.Audio(one_wav.cpu(), rate=32000))\n",
    "            caption = captions[idx]\n",
    "            audio_write(f'{output_dir}/{i}_{caption}', wav_diffusion[idx].cpu(), musicgen.sample_rate, strategy=\"loudness\", loudness_compressor=True)\n",
    "            ipd.display(ipd.Audio(wav_diffusion[idx].detach().cpu(), rate=32000))\n",
    "        clear_output(wait=True)\n",
    "    except Exception as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "musicgen2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
