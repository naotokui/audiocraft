{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MAGNeT\n",
    "Welcome to MAGNeT's demo jupyter notebook. \n",
    "Here you will find a self-contained example of how to use MAGNeT for music/sound-effect generation.\n",
    "\n",
    "First, we start by initializing MAGNeT for music generation, you can choose a model from the following selection:\n",
    "1. facebook/magnet-small-10secs - a 300M non-autoregressive transformer capable of generating 10-second music conditioned on text.\n",
    "2. facebook/magnet-medium-10secs - 1.5B parameters, 10 seconds music samples.\n",
    "3. facebook/magnet-small-30secs - 300M parameters, 30 seconds music samples.\n",
    "4. facebook/magnet-medium-30secs - 1.5B parameters, 30 seconds music samples.\n",
    "\n",
    "We will use the `facebook/magnet-small-10secs` variant for the purpose of this demonstration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import openai\n",
    "import json5\n",
    "\n",
    "# Initialize OpenAI API key\n",
    "openai.api_key = \"\"  # Replace with your actual API key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"\"I need text prompts for MusicGen, text-to-music model. Think step by step!    Please give me 3 text promots in a python array with a comment. one for each item in this array, (rhythm, melody, bass).    BPM should be inbetween 110 to 170. Be specific, get creative and use random instruments!     All three prompts should refleact the input parameters: \n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# prompt_input = f\"\"\"\"\"\n",
    "# Summerize '{item['text']}' and format the caption with other information into a JSON file.\n",
    "#\"\"\"\"\"\n",
    "example_output = {\n",
    "    \"comment\": \"Yeah, so this is a really cool track. It's got a great beat and a really catchy melody.The bassline is super funky and the whole thing just makes you want to dance. It's got a real African vibe to it, with the percussion drums and the 808 bass. The Shakuhachi adds a nice touch of Japanese flair. The koto melody is really beautiful and the bassline is just so funky. It's a really cool track and I think it would be perfect for a dance party or a club night. \",\n",
    "    \"captions\": [\n",
    "        \"Minimal percussion drums with 808 bass, influenced by early 90's chicago house, bpm 120\",\n",
    "        \"Japanese koto melody with jazz influence, tribal vibes for rituals, bpm 120\",\n",
    "        \"A very funky minimal jazzy bassline, good for big parties, bpm 120\"\n",
    "    ]   \n",
    "}\n",
    "\n",
    "params = [\"aggressive\", \"minimal\", \"experimental\", \"dubby\", \"jazzy\", \"pop\"]\n",
    "\n",
    "example_params = {\n",
    "    \"aggressive\": 0.,\n",
    "    \"minimal\": 0.8,\n",
    "    \"experimental\": 0.0,\n",
    "    \"dubby\": 0.0,\n",
    "    \"jazzy\": 1.0,\n",
    "    \"pop\": 0.2 \n",
    "}\n",
    "\n",
    "prompt_sample = f\"\"\"\"\"I need text prompts for MusicGen, text-to-music model. Think step by step!\\\n",
    "    Please give me 3 text promots in a python array with a comment. one for each item in this array, (rhythm, melody, bass).\\\n",
    "    BPM should be inbetween 110 to 170. Be specific, get creative and use random instruments! \\\n",
    "    All three prompts should refleact the input parameters: \n",
    "\"\"\"\"\"\n",
    "\n",
    "print(prompt_sample)\n",
    "\n",
    "isFirst = True\n",
    "\n",
    "def get_captions(settings):\n",
    "    global isFirst\n",
    "    # Query\n",
    "\n",
    "    param_settings =  dict(zip(params, settings))\n",
    "    print(param_settings) \n",
    "       \n",
    "    if isFirst or 1:\n",
    "        response = openai.ChatCompletion.create(\n",
    "            model=\"gpt-3.5-turbo\",\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": \"You are a world-famous dance music DJ performing at the biggest music festival.\"},\n",
    "                {\"role\": \"user\", \"content\": f\"{prompt_sample} {example_params}\"},\n",
    "                {\"role\": \"assistant\", \"content\": f\"{example_output}\"},\n",
    "                {\"role\": \"user\", \"content\": f\"{prompt_sample} {param_settings}\"},\n",
    "            ]\n",
    "        )\n",
    "    else:\n",
    "        response = openai.ChatCompletion.create(\n",
    "            model=\"gpt-3.5-turbo\",\n",
    "            messages=[\n",
    "                # {\"role\": \"system\", \"content\": \"You are a world-famous dance music DJ.\"},\n",
    "                # {\"role\": \"user\", \"content\": f\"{prompt_sample}\"},\n",
    "                # {\"role\": \"assistant\", \"content\": f\"{example_captions}\"},\n",
    "                {\"role\": \"user\", \"content\": f\"{prompt_sample}\"},\n",
    "            ]\n",
    "        )\n",
    "        isFirst = False\n",
    "\n",
    "    #print(response)\n",
    "\n",
    "    # Extract caption from API response\n",
    "    json_output = response['choices'][0]['message']['content'].strip()\n",
    "#    json_output = json_output.replace('\\'', '\\\"') \n",
    "    json_output = json5.loads(json_output)\n",
    "    print(json_output)\n",
    "\n",
    "    # parse the output\n",
    "    comment = json_output[\"comment\"]\n",
    "    captions = json_output[\"captions\"]\n",
    "    if len(captions) == 3:\n",
    "        captions[1] = \"no drums. \" + captions[1]\n",
    "        captions[2] = \"bassline only, \" + captions[2]\n",
    "\n",
    "    return comment, captions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'aggressive': 0.5, 'minimal': 0.5, 'experimental': 0.5, 'dubby': 0.5, 'jazzy': 0.5, 'pop': 0.5}\n",
      "{'comment': \"This track is a wild experiment in sound. The rhythm is aggressive and in your face, with heavy bass and sharp percussion. The melody is experimental, with dissonant tones and unexpected twists. The bassline is dubby and deep, rumbling beneath the chaotic mix of sounds. It's a jazzy, pop-influenced track that defies convention and pushes boundaries.\", 'captions': ['Aggressive industrial rhythm with distorted bass, BPM 150', 'Experimental electronic melody with glitchy effects, BPM 140', 'Dubby sub bassline with syncopated rhythms, BPM 130']}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(\"This track is a wild experiment in sound. The rhythm is aggressive and in your face, with heavy bass and sharp percussion. The melody is experimental, with dissonant tones and unexpected twists. The bassline is dubby and deep, rumbling beneath the chaotic mix of sounds. It's a jazzy, pop-influenced track that defies convention and pushes boundaries.\",\n",
       " ['Aggressive industrial rhythm with distorted bass, BPM 150',\n",
       "  'no drums. Experimental electronic melody with glitchy effects, BPM 140',\n",
       "  'bassline only, Dubby sub bassline with syncopated rhythms, BPM 130'])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_captions([0.5,0.5,0.5,0.5,0.5,0.5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nao/anaconda3/envs/mgen/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from audiocraft.models import MAGNeT\n",
    "import torch, torchaudio\n",
    "from audiocraft.utils.notebook import display_audio\n",
    "from audiocraft.data.audio import audio_write\n",
    "\n",
    "model = MAGNeT.get_pretrained('facebook/magnet-small-30secs')\n",
    "\n",
    "model.set_generation_params(\n",
    "    use_sampling=True,\n",
    "    top_k=0,\n",
    "    top_p=0.9,\n",
    "    temperature=3.0,\n",
    "    max_cfg_coef=10.0,\n",
    "    min_cfg_coef=1.0,\n",
    "    decoding_steps=[int(20 * model.lm.cfg.dataset.segment_duration // 10),  10, 10, 10],\n",
    "    span_arrangement='stride1'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, let us configure the generation parameters. Specifically, you can control the following:\n",
    "* `use_sampling` (bool, optional): use sampling if True, else do argmax decoding. Defaults to True.\n",
    "* `top_k` (int, optional): top_k used for sampling. Defaults to 0.\n",
    "* `top_p` (float, optional): top_p used for sampling, when set to 0 top_k is used. Defaults to 0.9.\n",
    "* `temperature` (float, optional): Initial softmax temperature parameter. Defaults to 3.0.\n",
    "* `max_clsfg_coef` (float, optional): Initial coefficient used for classifier free guidance. Defaults to 10.0.\n",
    "* `min_clsfg_coef` (float, optional): Final coefficient used for classifier free guidance. Defaults to 1.0.\n",
    "* `decoding_steps` (list of n_q ints, optional): The number of iterative decoding steps, for each of the n_q RVQ codebooks.\n",
    "* `span_arrangement` (str, optional): Use either non-overlapping spans ('nonoverlap') or overlapping spans ('stride1') \n",
    "                                      in the masking scheme. \n",
    "\n",
    "When left unchanged, MAGNeT will revert to its default parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we can go ahead and start generating music given textual prompts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text-conditional Generation - Music"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def apply_fade(audio, sr, duration=.025):\n",
    "    # convert to audio indices (samples)\n",
    "    length = int(duration*sr)\n",
    "    end = audio.shape[0]\n",
    "    start = end - length\n",
    "\n",
    "    # compute fade out curve\n",
    "    # linear fade\n",
    "    fade_curve = np.linspace(1.0, 0.0, length)\n",
    "\n",
    "    # apply the curve\n",
    "    audio[start:end] = audio[start:end] * fade_curve\n",
    "\n",
    "    fade_curve = np.linspace(0.0, 1.0, length)\n",
    "\n",
    "    # apply the curve\n",
    "    audio[:length] = audio[:length] * fade_curve\n",
    "\n",
    "    return audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOOP Extraction\n",
    "from madmom.features.downbeats import DBNDownBeatTrackingProcessor\n",
    "from madmom.features.downbeats import RNNDownBeatProcessor\n",
    "import os\n",
    "import soundfile as sf\n",
    "import pyrubberband as pyrb\n",
    "import librosa\n",
    "\n",
    "proc = DBNDownBeatTrackingProcessor(beats_per_bar=4, fps = 100, verbose=False)\n",
    "\n",
    "def extract_loop(file_path, desired_bpm, num_bars=2):\n",
    "    try:\n",
    "        _, sr = librosa.core.load(file_path, sr=None) # sr = None will retrieve the original sampling rate = 44100\n",
    "    except:\n",
    "        print('load file failed')\n",
    "        return None\n",
    "    try:\n",
    "        act = RNNDownBeatProcessor(verbose=False)(file_path)\n",
    "        down_beat=proc(act, verbose=False) # [..., 2] 2d-shape numpy array\n",
    "    except Exception as exp:\n",
    "        print('except happended', exp)\n",
    "        return None\n",
    "    count = 0\n",
    "    name = file_path.replace('.wav', '')\n",
    "    for i in range(0, down_beat.shape[0]):\n",
    "        if down_beat[i][1] == 1 and i + 4*num_bars < down_beat.shape[0] and down_beat[i+4*num_bars][1] == 1:\n",
    "            start_time = down_beat[i][0]\n",
    "            end_time = down_beat[i + 4*num_bars][0]\n",
    "            count += 1\n",
    "            out_path = os.path.join(\"./\", f'{name}_{count}.wav')\n",
    "            print(out_path, \"outpath\")\n",
    "            y_one_bar, _ = librosa.core.load(file_path, offset=start_time, duration = end_time - start_time, sr=None)\n",
    "            # desired_duration = 60./desired_bpm * (4*num_bars)\n",
    "            # y_stretch = pyrb.time_stretch(y_one_bar, sr,  (end_time - start_time) / desired_duration)\n",
    "            y_one_bar = apply_fade(y_one_bar, sr)\n",
    "            sf.write(out_path, y_one_bar, sr)\n",
    "            return out_path\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from audiocraft.utils.notebook import display_audio\n",
    "\n",
    "batch_size = 3\n",
    "\n",
    "def _loop_gen(filepath, bpm, temperature=1.0, settings=[]):\n",
    "\n",
    "    try:\n",
    "        print(settings)\n",
    "        comment, descs = get_captions(settings)\n",
    "    except Exception as e:\n",
    "        print(\"Error: \", e) \n",
    "        comment, descs = \"\", [\"\",\"\",\"\"] #dummy captions\n",
    "\n",
    "    descs = descs[:batch_size]\n",
    "    print(descs)\n",
    "\n",
    "    #descs = None\n",
    "    # descs = [\"\", \"\", \"\"]\n",
    "\n",
    "    # prompt audio\n",
    "    prompt_waveform, prompt_sr = torchaudio.load(filepath)\n",
    "    prompt_duration = 60. / bpm * 4 * 2 # the first 2 bar \n",
    "    prompt_waveform = prompt_waveform[..., :int(prompt_duration * prompt_sr)]\n",
    "    prompt_waveform = prompt_waveform[None, ...].repeat(batch_size, 1, 1)\n",
    "\n",
    "    # desc = [description] * batch_size\n",
    "    output = model.generate_continuation(prompt_waveform, prompt_sample_rate=prompt_sr, \n",
    "                                         progress=True, return_tokens=True, descriptions=descs)\n",
    "    # output = model.generate_continuation(prompt_waveform, prompt_sample_rate=prompt_sr, descriptions=descriptions, \n",
    "                                        #  progress=True, return_tokens=True)\n",
    "    print(\"generated\", output.shape)\n",
    "\n",
    "    sr = model.sample_rate\n",
    "    start_pos = int(prompt_duration * sr)  # skip the first 2 bars\n",
    "    display_audio(output[0], sample_rate=32000)\n",
    "\n",
    "    outpaths = []\n",
    "    for index in range(batch_size):\n",
    "        file_path = \"/mnt/c/tmp/output%d\" % index\n",
    "        # start_pos = 0\n",
    "        output_data = output[0][index].cpu().squeeze()[start_pos:]\n",
    "        audio_write(file_path, output_data, sr, strategy=\"loudness\", loudness_compressor=True)\n",
    "        outpath = extract_loop(file_path + \".wav\", bpm, num_bars=4)\n",
    "        if outpath:        \n",
    "            client.send_message(\"/prompt\", (index, descs[index]))\n",
    "        outpaths.append(outpath)\n",
    "\n",
    "    return outpaths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 68\u001b[0m\n\u001b[1;32m     65\u001b[0m server \u001b[38;5;241m=\u001b[39m osc_server\u001b[38;5;241m.\u001b[39mThreadingOSCUDPServer(\n\u001b[1;32m     66\u001b[0m     (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m172.17.140.208\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;241m10026\u001b[39m), dispatcher)\n\u001b[1;32m     67\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mServing on \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(server\u001b[38;5;241m.\u001b[39mserver_address))\n\u001b[0;32m---> 68\u001b[0m \u001b[43mserver\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mserve_forever\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/mgen/lib/python3.8/socketserver.py:232\u001b[0m, in \u001b[0;36mBaseServer.serve_forever\u001b[0;34m(self, poll_interval)\u001b[0m\n\u001b[1;32m    229\u001b[0m selector\u001b[38;5;241m.\u001b[39mregister(\u001b[38;5;28mself\u001b[39m, selectors\u001b[38;5;241m.\u001b[39mEVENT_READ)\n\u001b[1;32m    231\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__shutdown_request:\n\u001b[0;32m--> 232\u001b[0m     ready \u001b[38;5;241m=\u001b[39m \u001b[43mselector\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mselect\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpoll_interval\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    233\u001b[0m     \u001b[38;5;66;03m# bpo-35017: shutdown() called during select(), exit immediately.\u001b[39;00m\n\u001b[1;32m    234\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__shutdown_request:\n",
      "File \u001b[0;32m~/anaconda3/envs/mgen/lib/python3.8/selectors.py:415\u001b[0m, in \u001b[0;36m_PollLikeSelector.select\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    413\u001b[0m ready \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    414\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 415\u001b[0m     fd_event_list \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_selector\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpoll\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    416\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mInterruptedError\u001b[39;00m:\n\u001b[1;32m    417\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ready\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# %%\n",
    "import os \n",
    "import time\n",
    "from threading import Thread\n",
    "from pythonosc import dispatcher\n",
    "from pythonosc import osc_server, udp_client\n",
    "from IPython.display import clear_output\n",
    "\n",
    "isGenerating = False\n",
    "\n",
    "def loop_gen(unused_addr, filepath, bpm=120., temperature=1.0, p1=0.5, p2=0.5, p3=0.5, p4=0.5, p5=0.5, p6=0.5):\n",
    "    global isGenerating\n",
    "\n",
    "    if isGenerating: # avoid duplicate generation\n",
    "        return\n",
    "    \n",
    "    # parameters\n",
    "    #model.set_generation_params(temperature=temperature)\n",
    "\n",
    "    isGenerating = True\n",
    "    filepath = filepath.replace(\"C:/\", \"/mnt/c/\") # file path is in windows format\n",
    "\n",
    "    if os.path.exists(filepath):\n",
    "        try:\n",
    "            settings = [p1, p2, p3, p4, p5, p6]\n",
    "            outpaths = _loop_gen(filepath, bpm, temperature, settings)\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            outpaths = None\n",
    "        # if outpath is not None:    \n",
    "        client.send_message(\"/generated\", (1))\n",
    "        client.send_message(\"/generated\", (1))\n",
    "    else:\n",
    "        print(\"file not found\", filepath)\n",
    "\n",
    "    clear_output(wait=True)\n",
    "    isGenerating = False\n",
    "\n",
    "dispatcher = dispatcher.Dispatcher()\n",
    "dispatcher.map(\"/loop_gen\", loop_gen)\n",
    "\n",
    "#%%\n",
    "\n",
    "# client = udp_client.SimpleUDPClient('127.0.1.1', 10018)\n",
    "client = udp_client.SimpleUDPClient('172.17.128.1', 10018)\n",
    "\n",
    "\n",
    "def beacon():\n",
    "    while True:\n",
    "        client.send_message(\"/heartbeat\", 1)\n",
    "        time.sleep(1.0)\n",
    "def generating():\n",
    "    while True:\n",
    "        if isGenerating:\n",
    "            client.send_message(\"/generating\", 1)\n",
    "        time.sleep(0.333)\n",
    "\n",
    "t1 = Thread(target = beacon)\n",
    "t2 = Thread(target = generating)\n",
    "t1.setDaemon(True)\n",
    "t2.setDaemon(True)\n",
    "t1.start()\n",
    "t2.start()\n",
    "\n",
    "server = osc_server.ThreadingOSCUDPServer(\n",
    "    ('172.17.140.208', 10026), dispatcher)\n",
    "print(\"Serving on {}\".format(server.server_address))\n",
    "server.serve_forever()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mgen",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
